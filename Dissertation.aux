\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\catcode `"\active 
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\xpginauxfiletrue }
\@writefile{lof}{\xpginauxfiletrue }
\@writefile{lot}{\xpginauxfiletrue }
\@writefile{toc}{\selectlanguage *[variant=us]{english}}
\@writefile{toc}{\selectlanguage *[variant=us]{english}}
\citation{StateAI2025}
\citation{kindigAIPowerConsumption}
\citation{maassNetworksSpikingNeurons1997}
\citation{maassComputationalPowerCircuits2004}
\citation{merollaMillionSpikingneuronIntegrated2014}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces (a) 2nd generation neuron. (b) 3rd generation neuron.}}{3}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:second_vs_third_gen}{{1}{3}{(a) 2nd generation neuron. (b) 3rd generation neuron}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\newlabel{introduction}{{1}{3}{Introduction}{section.1}{}}
\citation{SpikingHeidelbergDigits}
\citation{PapersCodeSSC}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Problem to Solve}{4}{subsection.1.1}\protected@file@percent }
\newlabel{problem-to-solve}{{1.1}{4}{Problem to Solve}{subsection.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Spiking Heidelberg Digits Dataset}{4}{subsection.1.2}\protected@file@percent }
\newlabel{spiking-heidelberg-digits-dataset}{{1.2}{4}{Spiking Heidelberg Digits Dataset}{subsection.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Spiking Neuron Model}{4}{section.2}\protected@file@percent }
\newlabel{spiking-neuron-model}{{2}{4}{Spiking Neuron Model}{section.2}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Diagram of neuron membrane.}}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig:membrane_diagram}{{2}{5}{Diagram of neuron membrane}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Hodgkin--Huxley}{5}{subsection.2.1}\protected@file@percent }
\newlabel{hodgkinhuxley}{{2.1}{5}{Hodgkin--Huxley}{subsection.2.1}{}}
\newlabel{eqn:hh1}{{1}{6}{Hodgkin--Huxley}{equation.2.1}{}}
\newlabel{eqn:hh2}{{2}{6}{Hodgkin--Huxley}{equation.2.2}{}}
\newlabel{eqn:hh3}{{3}{6}{Hodgkin--Huxley}{equation.2.3}{}}
\newlabel{eqn:hh4}{{4}{6}{Hodgkin--Huxley}{equation.2.4}{}}
\newlabel{eqn:hh5}{{5}{6}{Hodgkin--Huxley}{equation.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Leaky Integrate-and-Fire Neuron}{6}{subsection.2.2}\protected@file@percent }
\newlabel{leaky-integrate-and-fire-neuron}{{2.2}{6}{Leaky Integrate-and-Fire Neuron}{subsection.2.2}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Response of the HH model (blue) to a 5ms step function (red).}}{7}{figure.caption.4}\protected@file@percent }
\newlabel{fig:response_of_hh_1}{{3}{7}{Response of the HH model (blue) to a 5ms step function (red)}{figure.caption.4}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Response of the HH model (blue) to a 10ms step function (red).}}{7}{figure.caption.5}\protected@file@percent }
\newlabel{fig:response_of_hh_15}{{4}{7}{Response of the HH model (blue) to a 10ms step function (red)}{figure.caption.5}{}}
\citation{izhikevichSimpleModelSpiking2003}
\citation{izhikevichSimpleModelSpiking2003}
\citation{izhikevichWhichModelUse2004}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Response of the HH model (blue) to a 15ms step function (red).}}{8}{figure.caption.6}\protected@file@percent }
\newlabel{fig:response_of_hh_2}{{5}{8}{Response of the HH model (blue) to a 15ms step function (red)}{figure.caption.6}{}}
\newlabel{eqn:lif1}{{6}{8}{Leaky Integrate-and-Fire Neuron}{equation.2.6}{}}
\newlabel{eqn:lif2}{{7}{8}{Leaky Integrate-and-Fire Neuron}{equation.2.7}{}}
\newlabel{eqn:lif3}{{8}{8}{Leaky Integrate-and-Fire Neuron}{equation.2.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Izhikevich}{8}{subsection.2.3}\protected@file@percent }
\newlabel{izhikevich}{{2.3}{8}{Izhikevich}{subsection.2.3}{}}
\newlabel{eqn:iz1}{{9}{8}{Izhikevich}{equation.2.9}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces LIF neuron plot of \(V_{mem}\).}}{9}{figure.caption.7}\protected@file@percent }
\newlabel{fig:second_vs_third_gen}{{6}{9}{LIF neuron plot of \(V_{mem}\)}{figure.caption.7}{}}
\citation{izhikevichSimpleModelSpiking2003}
\citation{izhikevichWhichModelUse2004}
\citation{dengMachineLearningParadigms2013,hintonDeepNeuralNetworks2012}
\newlabel{eqn:iz2}{{10}{10}{Izhikevich}{equation.2.10}{}}
\newlabel{eqn:iz3}{{11}{10}{Izhikevich}{equation.2.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Neural Networks}{10}{subsection.2.4}\protected@file@percent }
\newlabel{neural-networks}{{2.4}{10}{Neural Networks}{subsection.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Training Neural Networks}{10}{section.3}\protected@file@percent }
\newlabel{training-neural-networks}{{3}{10}{Training Neural Networks}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Backpropagation}{10}{subsection.3.1}\protected@file@percent }
\newlabel{backpropagation}{{3.1}{10}{Backpropagation}{subsection.3.1}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Diagram of a 3 layer neural network. The weights of the synapses are visualised by the colours of the connections.}}{11}{figure.caption.8}\protected@file@percent }
\newlabel{fig:simple_neural_network}{{7}{11}{Diagram of a 3 layer neural network. The weights of the synapses are visualised by the colours of the connections}{figure.caption.8}{}}
\newlabel{eqn:loss_mse}{{12}{11}{Backpropagation}{equation.3.12}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces (a) ANN neuron (b) SNN neuron}}{12}{figure.caption.9}\protected@file@percent }
\newlabel{fig:gradient_descent_3d_axis}{{8}{12}{(a) ANN neuron (b) SNN neuron}{figure.caption.9}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \(x\) is the input vector of length 3. \(h\) is the hidden layer of length 6. \(W^{x-h}\) is the matrix containing the values of each of the weights connecting \(x\) and \(h\), thus it is of size 3 by 6. \(y\) is the output vector of length 3. \(W^{h-y}\) is the matrix containing the values of each of the weights connecting \(h\) and \(y\). thus it is of size 6 by 3.}}{13}{figure.caption.10}\protected@file@percent }
\newlabel{fig:mlp_3_layer}{{9}{13}{\(x\) is the input vector of length 3. \(h\) is the hidden layer of length 6. \(W^{x-h}\) is the matrix containing the values of each of the weights connecting \(x\) and \(h\), thus it is of size 3 by 6. \(y\) is the output vector of length 3. \(W^{h-y}\) is the matrix containing the values of each of the weights connecting \(h\) and \(y\). thus it is of size 6 by 3}{figure.caption.10}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Matrix multiplication visualisation.}}{14}{figure.caption.11}\protected@file@percent }
\newlabel{fig:matrix_of_network}{{10}{14}{Matrix multiplication visualisation}{figure.caption.11}{}}
\newlabel{eqn:weighted_sum}{{13}{14}{Backpropagation}{equation.3.13}{}}
\citation{wuDeepSpikingNeural2020,bittarSurrogateGradientSpiking2022}
\citation{bellecBiologicallyInspiredAlternatives2019}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Loss function 3D surface being descended.}}{15}{figure.caption.12}\protected@file@percent }
\newlabel{fig:gradient_descent_3d}{{11}{15}{Loss function 3D surface being descended}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Spiking Neural Network Training}{15}{subsection.3.2}\protected@file@percent }
\newlabel{spiking-neural-network-training}{{3.2}{15}{Spiking Neural Network Training}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}ANN-to-SNN Conversion}{15}{subsubsection.3.2.1}\protected@file@percent }
\newlabel{ann-to-snn-conversion}{{3.2.1}{15}{ANN-to-SNN Conversion}{subsubsection.3.2.1}{}}
\citation{neftciSurrogateGradientLearning2019}
\citation{bellecBiologicallyInspiredAlternatives2019}
\citation{bittarSurrogateGradientSpiking2022,zhouDirectTrainingHighperformance2024}
\citation{bittarSurrogateGradientSpiking2022}
\citation{zhouDirectTrainingHighperformance2024}
\citation{arnaudyargaAcceleratingSpikingNeural2025,yargaAcceleratingSNNTraining2023}
\citation{arnaudyargaAcceleratingSpikingNeural2025}
\citation{arnaudyargaAcceleratingSpikingNeural2025,yargaAcceleratingSNNTraining2023}
\citation{yargaAcceleratingSNNTraining2023}
\citation{maasNetworksSpikingNeurons1997}
\citation{koopmanOvercomingLimitationsLayer2024,zhongSPikESSMSparsePrecise2024}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Backpropagation-Through-Time}{16}{subsubsection.3.2.2}\protected@file@percent }
\newlabel{backpropagation-through-time}{{3.2.2}{16}{Backpropagation-Through-Time}{subsubsection.3.2.2}{}}
\newlabel{parallelisable-lif}{{3.2.2}{16}{Parallelisable LIF}{section*.13}{}}
\@writefile{toc}{\contentsline {paragraph}{Parallelisable LIF}{16}{section*.13}\protected@file@percent }
\citation{bellecEligibilityTracesProvide2019}
\citation{bellecEligibilityTracesProvide2019a,rostamiEpropSpiNNaker22022}
\citation{bellecEligibilityTracesProvide2019}
\citation{veenIncludingSTDPEligibility2021}
\citation{rostamiEpropSpiNNaker22022a}
\citation{rostamiEpropSpiNNaker22022,turn0search8}
\citation{bellecEligibilityTracesProvide2019}
\citation{bellecEligibilityTracesProvide2019a}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Matrix multiplication visualisation.}}{17}{figure.caption.14}\protected@file@percent }
\newlabel{fig:parallel_lif}{{12}{17}{Matrix multiplication visualisation}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Eligibility Propagation}{17}{subsubsection.3.2.3}\protected@file@percent }
\newlabel{eligibility-propagation}{{3.2.3}{17}{Eligibility Propagation}{subsubsection.3.2.3}{}}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces LTP and LTD}}{18}{figure.caption.15}\protected@file@percent }
\newlabel{fig:stdp_ltp_ltd}{{13}{18}{LTP and LTD}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Spike-Time-Dependent-Plasticity}{18}{subsubsection.3.2.4}\protected@file@percent }
\newlabel{spike-time-dependent-plasticity}{{3.2.4}{18}{Spike-Time-Dependent-Plasticity}{subsubsection.3.2.4}{}}
\citation{chenEssentialCharacteristicsMemristors2023}
\citation{liResearchProgressNeural2023}
\citation{weilenmannSingleNeuromorphicMemristor2024}
\citation{vlasovSpokenDigitsClassification2022}
\citation{sboevSpokenDigitsClassification2024}
\citation{guoDirectLearningbasedDeep2023}
\citation{liuSSTDPSupervisedSpike2021}
\citation{leeTrainingDeepSpiking2018}
\citation{bittarSurrogateGradientSpiking2022a}
\citation{nowotnyLossShapingEnhances2025}
\citation{wunderlichEventbasedBackpropagationCan2021}
\citation{shoesmithEventpropTrainingEfficient2025}
\citation{nowotnyLossShapingEnhances2025}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.5}Eventprop}{19}{subsubsection.3.2.5}\protected@file@percent }
\newlabel{eventprop}{{3.2.5}{19}{Eventprop}{subsubsection.3.2.5}{}}
\citation{nowotnyLossShapingEnhances2025}
\@writefile{lof}{\setforeignlanguage {english}}
\@writefile{lot}{\setforeignlanguage {english}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Spikes propagated forward according to LIF neuron dynamics. Error signals propagated backward according to the adjoint method.}}{20}{figure.caption.16}\protected@file@percent }
\newlabel{fig:eventprop_backpropagation}{{14}{20}{Spikes propagated forward according to LIF neuron dynamics. Error signals propagated backward according to the adjoint method}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Improving Training Using New Loss}{20}{section.4}\protected@file@percent }
\newlabel{improving-training-using-new-loss}{{4}{20}{Improving Training Using New Loss}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Training Process}{20}{section.5}\protected@file@percent }
\newlabel{training-process}{{5}{20}{Training Process}{section.5}{}}
\citation{nowotnyLossShapingEnhances2025}
\bibstyle{IEEEtran}
\bibdata{references}
\bibcite{StateAI2025}{{1}{}{{}}{{}}}
\bibcite{kindigAIPowerConsumption}{{2}{}{{}}{{}}}
\bibcite{maassNetworksSpikingNeurons1997}{{3}{}{{}}{{}}}
\bibcite{maassComputationalPowerCircuits2004}{{4}{}{{}}{{}}}
\bibcite{merollaMillionSpikingneuronIntegrated2014}{{5}{}{{}}{{}}}
\bibcite{SpikingHeidelbergDigits}{{6}{}{{}}{{}}}
\bibcite{izhikevichSimpleModelSpiking2003}{{7}{}{{}}{{}}}
\bibcite{izhikevichWhichModelUse2004}{{8}{}{{}}{{}}}
\bibcite{dengMachineLearningParadigms2013}{{9}{}{{}}{{}}}
\newlabel{eqn:lsumexp}{{19}{21}{Training Process}{equation.5.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Model Description}{21}{section.6}\protected@file@percent }
\newlabel{model-description}{{6}{21}{Model Description}{section.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Bayesian optimisation of hyperparameters}{21}{section.7}\protected@file@percent }
\newlabel{bayesian-optimisation-of-hyperparameters}{{7}{21}{Bayesian optimisation of hyperparameters}{section.7}{}}
\bibcite{hintonDeepNeuralNetworks2012}{{10}{}{{}}{{}}}
\bibcite{wuDeepSpikingNeural2020}{{11}{}{{}}{{}}}
\bibcite{bittarSurrogateGradientSpiking2022}{{12}{}{{}}{{}}}
\bibcite{bellecBiologicallyInspiredAlternatives2019}{{13}{}{{}}{{}}}
\bibcite{neftciSurrogateGradientLearning2019}{{14}{}{{}}{{}}}
\bibcite{zhouDirectTrainingHighperformance2024}{{15}{}{{}}{{}}}
\bibcite{arnaudyargaAcceleratingSpikingNeural2025}{{16}{}{{}}{{}}}
\bibcite{yargaAcceleratingSNNTraining2023}{{17}{}{{}}{{}}}
\bibcite{maasNetworksSpikingNeurons1997}{{18}{}{{}}{{}}}
\bibcite{koopmanOvercomingLimitationsLayer2024}{{19}{}{{}}{{}}}
\bibcite{zhongSPikESSMSparsePrecise2024}{{20}{}{{}}{{}}}
\bibcite{bellecEligibilityTracesProvide2019}{{21}{}{{}}{{}}}
\bibcite{bellecEligibilityTracesProvide2019a}{{22}{}{{}}{{}}}
\bibcite{rostamiEpropSpiNNaker22022}{{23}{}{{}}{{}}}
\bibcite{veenIncludingSTDPEligibility2021}{{24}{}{{}}{{}}}
\bibcite{rostamiEpropSpiNNaker22022a}{{25}{}{{}}{{}}}
\bibcite{chenEssentialCharacteristicsMemristors2023}{{26}{}{{}}{{}}}
\bibcite{liResearchProgressNeural2023}{{27}{}{{}}{{}}}
\bibcite{weilenmannSingleNeuromorphicMemristor2024}{{28}{}{{}}{{}}}
\bibcite{vlasovSpokenDigitsClassification2022}{{29}{}{{}}{{}}}
\bibcite{sboevSpokenDigitsClassification2024}{{30}{}{{}}{{}}}
\bibcite{guoDirectLearningbasedDeep2023}{{31}{}{{}}{{}}}
\bibcite{liuSSTDPSupervisedSpike2021}{{32}{}{{}}{{}}}
\bibcite{leeTrainingDeepSpiking2018}{{33}{}{{}}{{}}}
\bibcite{bittarSurrogateGradientSpiking2022a}{{34}{}{{}}{{}}}
\bibcite{nowotnyLossShapingEnhances2025}{{35}{}{{}}{{}}}
\bibcite{shoesmithEventpropTrainingEfficient2025}{{36}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{toc}{\xpginauxfilefalse }
\@writefile{lof}{\xpginauxfilefalse }
\@writefile{lot}{\xpginauxfilefalse }
\gdef \@abspage@last{23}
